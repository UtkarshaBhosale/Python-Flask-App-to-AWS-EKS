# Python-Flask-App-to-AWS-EKS-using-CI-CD

## Project Description

This project demonstrates a complete **CI/CD pipeline** for deploying a Python Flask web service to **Amazon Elastic Kubernetes Service (EKS)** using modern Infrastructure-as-Code and containerization practices.
The goal is to showcase how to build, test, package, and deploy a Flask application in a fully automated manner, leveraging AWS and open-source DevOps tools.

### Key Components

* **Flask Application**: A lightweight Python web service serving a RESTful API.
* **Infrastructure as Code (IaC)**:

  * **Terraform** provisions the entire AWS environment, including:

    * **VPC** with subnets, Internet gateway, and security groups.
    * **EKS Cluster** for Kubernetes workloads.
    * **ECR Repository** for container image storage.
* **Containerization**: A production-ready **Dockerfile** builds the Flask application into a portable container image.
* **CI/CD Pipeline**:

  * **Jenkins** orchestrates build, test, and deployment stages:

    1. **Build & Unit Test** ‚Äì Install dependencies and run tests.
    2. **Docker Build & Push** ‚Äì Build the image and push to Amazon ECR.
    3. **Deploy to EKS** ‚Äì Apply Kubernetes manifests to update the running application.
* **Kubernetes Manifests**: YAML files define the Deployment, Service, and related resources for running the Flask app on EKS.

### Objectives

* Provide a reproducible workflow for deploying containerized Python web apps to AWS.
* Demonstrate end-to-end automation, from infrastructure provisioning to application deployment.
* Serve as a reference architecture for teams adopting cloud-native practices.

---

### Project Structure
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ Jenkinsfile
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ deploy
‚îÇ   ‚îî‚îÄ‚îÄ deploy.sh
‚îú‚îÄ‚îÄ images/
‚îú‚îÄ‚îÄ k8s
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îî‚îÄ‚îÄ service.yaml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ terraform
‚îÇ   ‚îú‚îÄ‚îÄ ecr.tf
‚îÇ   ‚îú‚îÄ‚îÄ eks.tf
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îú‚îÄ‚îÄ providers.tf
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îî‚îÄ‚îÄ vpc.tf
‚îî‚îÄ‚îÄ test_app.py

### üê≥ Steps to Deploy an Application on Docker
## Dockerfile:
``` bash
FROM python:3.13-slim AS builder

WORKDIR /app

COPY requirements.txt .

RUN pip install --upgrade pip && \
    pip install --prefix=/install -r requirements.txt

COPY . .

FROM python:3.13-alpine

RUN apk add --no-cache libgcc libstdc++ musl

WORKDIR /app

COPY --from=builder /install /usr/local
COPY --from=builder /app /app

EXPOSE 5000

CMD ["gunicorn", "--bind", "0.0.0.0:5000", "app:app"]

```
### Local Testing & Validation
## Build the Docker image:
```bash
docker build --no-cache -t utkarsha0601/mern-application/utkarsha-flask-app:27.09 .
```

<img width="1916" height="676" alt="image" src="https://github.com/user-attachments/assets/e9378821-b891-4dfa-9f64-90e17d861233" />

```bash
docker container run -d -p 5000:5000 --name utkarsha-flask-app utkarsha0601/mern-application/utkarsha-flask-app:27.09
```

<img width="1107" height="322" alt="image" src="https://github.com/user-attachments/assets/5b562193-f48b-4957-8f0e-9e1f518add80" />


### üõ† Terraform Infrastructure Provisioning

Terraform is used to provision AWS infrastructure for the application, including VPC, ECR, and EKS.

Project Directory Structure

coding-assignment-prt/
‚îú‚îÄ‚îÄ terraform/
‚îÇ   ‚îú‚îÄ‚îÄ ecr.tf
‚îÇ   ‚îú‚îÄ‚îÄ eks.tf
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îú‚îÄ‚îÄ vpc.tf
‚îÇ   ‚îú‚îÄ‚îÄ backend.tf
‚îÇ   ‚îú‚îÄ‚îÄ providers.tf
‚îÇ   ‚îú‚îÄ‚îÄ user-data.sh


Define AWS Provider
File: terraform/providers.tf
```bash
terraform {
  required_version = ">= 1.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}
```

Define Variables
File: terraform/variables.tf
```bash
variable "aws_region" {
  description = "AWS region to deploy resources"
  type        = string
  default     = "ap-south-1"
}

variable "cluster_name" {
  description = "Name of the EKS cluster"
  type        = string
  default     = "utkarsha-eks-cluster"
}

variable "vpc_cidr" {
  description = "CIDR block for the VPC"
  type        = string
  default     = "10.0.0.0/16"
}

variable "public_subnet_cidrs" {
  description = "CIDR blocks for public subnets"
  type        = list(string)
  default     = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
}

variable "private_subnet_cidrs" {
  description = "CIDR blocks for private subnets"
  type        = list(string)
  default     = ["10.0.4.0/24", "10.0.5.0/24", "10.0.6.0/24"]
}

variable "azs" {
  description = "Availability Zones"
  type        = list(string)
  default     = ["ap-south-1a", "ap-south-1b"]
}

variable "ecr_repo_names" {
  description = "List of ECR repository names to create"
  type        = list(string)
  default     = ["utkarsha-app-repo"]
}
```

VPC
File: terraform/vpc.tf

```bash
# Create VPC
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_support   = true
  enable_dns_hostnames = true

  tags = {
    Name = "${var.cluster_name}-vpc"
  }
}

resource "aws_subnet" "public" {
  count                   = length(var.public_subnet_cidrs)
  vpc_id                  = aws_vpc.main.id
  cidr_block              = var.public_subnet_cidrs[count.index]
  availability_zone       = element(["ap-south-1a", "ap-south-1b"], count.index)  # Use the corrected AZs
  map_public_ip_on_launch = true
  tags = {
    Name = "public-subnet-${element(["a", "b"], count.index)}"
  }
}

# Create Internet Gateway
resource "aws_internet_gateway" "igw" {
  vpc_id = aws_vpc.main.id

  tags = {
    Name = "${var.cluster_name}-igw"
  }
}

# Create Public Route Table
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.igw.id
  }

  tags = {
    Name = "public-rt"
  }
}

# Associate Public Subnets with Public Route Table
resource "aws_route_table_association" "public" {
  count          = length(aws_subnet.public)
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}

```

<img width="1913" height="411" alt="image" src="https://github.com/user-attachments/assets/e5531bda-7afc-4a84-9cf3-760e0752be1a" />


ECR
File: terraform/ecr.tf

```bash
# Create ECR Repositories
resource "aws_ecr_repository" "repo" {
  for_each             = toset(var.ecr_repo_names)
  name                 = each.key
  image_tag_mutability = "MUTABLE" # Use "IMMUTABLE" for production

  image_scanning_configuration {
    scan_on_push = true # Enable automatic vulnerability scanning on push :cite[4]:cite[6]
  }

  encryption_configuration {
    encryption_type = "AES256" # Server-side encryption
  }

  tags = {
    Terraform   = "true"
    Environment = "dev"
  }
}

# Optional: Lifecycle Policy to clean up old images
resource "aws_ecr_lifecycle_policy" "repo_policy" {
  for_each   = toset(var.ecr_repo_names)
  repository = aws_ecr_repository.repo[each.key].name

  policy = jsonencode({
    rules = [{
      rulePriority = 1
      description  = "Keep last 30 images"
      selection = {
        tagStatus   = "any"
        countType   = "imageCountMoreThan"
        countNumber = 30
      }
      action = {
        type = "expire"
      }
    }]
  })
}
```

EKS
File: terraform/eks.tf

```bash
# IAM Role for EKS Cluster
resource "aws_iam_role" "eks_cluster_role" {
  name = "${var.cluster_name}-cluster-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Principal = {
          Service = "eks.amazonaws.com"
        }
        Action = "sts:AssumeRole"
      }
    ]
  })
}

# Attach AmazonEKSClusterPolicy to Cluster Role
resource "aws_iam_role_policy_attachment" "eks_cluster_policy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  role       = aws_iam_role.eks_cluster_role.name
}

# Create EKS Cluster
resource "aws_eks_cluster" "cluster" {
  name     = var.cluster_name
  role_arn = aws_iam_role.eks_cluster_role.arn
  version  = "1.30" # Specify your desired Kubernetes version

  vpc_config {
    subnet_ids = aws_subnet.public[*].id # Place control plane in private subnets
    # endpoint_private_access = true # Uncomment for private cluster
    # endpoint_public_access  = false # Uncomment for private cluster
  }

  depends_on = [aws_iam_role_policy_attachment.eks_cluster_policy]
}

# IAM Role for EKS Node Group
resource "aws_iam_role" "eks_node_role" {
  name = "${var.cluster_name}-node-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect = "Allow"
        Principal = {
          Service = "ec2.amazonaws.com"
        }
        Action = "sts:AssumeRole"
      }
    ]
  })
}

# Attach necessary policies to Node Role
resource "aws_iam_role_policy_attachment" "eks_worker_node_policy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
  role       = aws_iam_role.eks_node_role.name
}

resource "aws_iam_role_policy_attachment" "eks_cni_policy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
  role       = aws_iam_role.eks_node_role.name
}

resource "aws_iam_role_policy_attachment" "ecr_read_only_policy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  role       = aws_iam_role.eks_node_role.name
}

# Create EKS Managed Node Group
resource "aws_eks_node_group" "nodes" {
  cluster_name    = aws_eks_cluster.cluster.name
  node_group_name = "managed-nodes"
  node_role_arn   = aws_iam_role.eks_node_role.arn
  subnet_ids      = aws_subnet.public[*].id

  scaling_config {
    desired_size = 2
    max_size     = 3
    min_size     = 1
  }

  instance_types = ["t3.medium"]

  # Ensure the IAM Role permissions are created before and deleted after the Node Group handling
  depends_on = [
    aws_iam_role_policy_attachment.eks_worker_node_policy,
    aws_iam_role_policy_attachment.eks_cni_policy,
    aws_iam_role_policy_attachment.ecr_read_only_policy,
  ]
}

```


<img width="1919" height="531" alt="image" src="https://github.com/user-attachments/assets/80b6289a-151b-492d-ab18-19436e8319d3" />
<img width="1919" height="774" alt="image" src="https://github.com/user-attachments/assets/eef80f30-6610-474a-90b5-98d88aa0637d" />
<img width="1920" height="1358" alt="image" src="https://github.com/user-attachments/assets/fc0bfba6-72ce-4d31-b80c-4387a16a1e12" />
<img width="1916" height="448" alt="image" src="https://github.com/user-attachments/assets/d6c79972-12d4-47e2-b220-57fca0d3fbe3" />
<img width="1915" height="457" alt="image" src="https://github.com/user-attachments/assets/551a4ea0-ca6c-4447-b92a-024f31053ef9" />







üöÄ Deployment Steps
Configure AWS Credentials: Ensure AWS credentials are set in ~/.aws/credentials or as environment variables.

Initialize Terraform

```bash
terraform init
```
<img width="1600" height="474" alt="image" src="https://github.com/user-attachments/assets/5f327ede-6f63-434d-8b12-d88315a50388" />



Format and Validate:
```bash
terraform fmt
terraform validate
```
<img width="1501" height="144" alt="image" src="https://github.com/user-attachments/assets/b61248af-4482-4e1f-9897-0f3811541145" />


Preview Changes:
```bash
terraform plan
```
<img width="1777" height="872" alt="image" src="https://github.com/user-attachments/assets/d9d5c4a3-816b-4306-b756-cb7f616dcef2" />

Apply Configuration:

```bash
terraform apply
```
<img width="1316" height="854" alt="image" src="https://github.com/user-attachments/assets/2b0fc302-1c62-45ed-bba8-818a848583c8" />

Destroy Infrastructure (when needed): You can use destroy

```bash
terraform destroy
```

<img width="1538" height="793" alt="image" src="https://github.com/user-attachments/assets/9bd90bb5-b0d6-4c19-a867-0e8880a9833d" />


‚ò∏Ô∏è Steps to Deploy an Application on Kubernetes
üìÑ Create Deployment

File: k8s/deployment.yaml

```bash
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flask-deployment
  namespace: default
  labels:
    app: flask
spec:
  replicas: 2
  selector:
    matchLabels:
      app: flask
  template:
    metadata:
      labels:
        app: flask
    spec:
      containers:
      - name: flask-app
        image: <IMAGE_NAME>
        ports:
        - containerPort: 5000
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /
            port: 5000
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 5000
          initialDelaySeconds: 5
          periodSeconds: 5

```

üìå Apply Deployment
```bash
kubectl apply -f k8s/deployment.yaml
```



